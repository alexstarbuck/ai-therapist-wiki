---
title: General Description
sidebar_label: General desc.
tags:
  - eu
  - gajger
date_created: 2025-08-11 09:57
---
## Obvious, but powerful truth

- **People are already using AI as a therapist.**  
- But they’re doing it alone. Unseen. Unsupported.  
- With tools never meant for it.  
- And it’s only a matter of time before someone gets hurt — if it hasn’t happened already.

## The problem ISN'T that AI is being used for emotional support

It’s that **it’s happening without safety nets**:

- No domain adaptation;
- No escalation pathway;
- No awareness of user fragility;
- No trauma protocols;
- No bias mitigation;
- No continuity of care;
- No human oversight.


 >***Current state***: Self-triage tools are symptom checklists, rigid forms, or basic bots.  
> 
> ***Our innovation**: A human-like interface (verbal, non-verbal, emotionally responsive) that helps individuals feel heard, builds rapport, and guides them toward the right care pathway — in a safe, evidence-informed, modular environment."*

## Project Overview

**Working Title:** AI Assistant for Psychological Assessment, Guidance, and Support;  

**Funding Instrument:** EU Research and Development ([IRI S3 - Povećanje razvoja novih proizvoda i usluga koji proizlaze iz aktivnosti istraživanja i razvoja](https://eufondovi.gov.hr/poziv/?id=23d4b78c-ac5a-480b-908e-362f39fe8992)) – Croatia / EU Cohesion Policy;

This project aims to develop a prototype of a virtual psychotherapy assistant, powered by advanced multimodal artificial intelligence, delivered through a photorealistic, emotionally intelligent avatar.

Unlike chatbot-based applications, this system is designed to simulate authentic human interaction — including voice, facial expression, and psychological support protocols — with clinical supervision at its core.

At this stage, the system is not a replacement for psychotherapy, but a digital triage and support layer that can:

- Offer emotional support to individuals in need;
- Guide users toward real-world clinical pathways when necessary;
- Support clinicians and researchers in exploring how AI can ethically assist in mental health care;

The service will provide emotionally intelligent, conversational mental health support, accessible 24/7, globally.

---
## Key Challenges Addressed

- Growing demand for mental health support exceeds the capacity of available professionals;
- Individuals—especially adolescents and young adults—turn to unregulated AI tools lacking clinical validation;
- Stigma, cost, and lack of access prevent many from seeking timely psychological guidance;
- There is an urgent need for safe, science-backed digital tools to assist in early detection, triage, and referral;

---
## Consortium (proposed)

- [**Zeraxo d.o.o.**](https://zeraxo.com) – Project coordinator and lead technical partner (design and development, UX/UI, AI integration);
- [**Društvo za Psihološku pomoć**](https://dpp.hr/) - Partner (guidelines and recommendations, support during project duration);
- [**Department of Psychology**](https://psihologija.ffzg.unizg.hr/) - Faculty of Humanities and Social Sciences, University of Zagreb (psychology expertise, methodology design, validation studies);
- [**University Psychiatric Hospital Vrapče**](https://bolnica-vrapce.hr/) – Clinical partner (clinical oversight, escalation protocols, pilot testing, ethics board);
---
## Strategic Framing

The platform is positioned not as a fully autonomous psychotherapist, but as a research-driven triage and augmentation tool:

- For preliminary psychological support, especially for those who otherwise would not seek help;
- For clinical escalation, referring high-risk users toward licensed professionals;
- For data-driven psychological research, enabling structured studies into digital therapeutic interfaces;
---
## Project Goals

- Develop a clinically-informed MVP with co-authored protocols;
- Pilot the platform with academic and hospital stakeholders in Croatia;
- Conduct psychological and ethical validation studies;
- Establish long-term scientific collaboration in AI + mental health;
- Position the platform for further development and EU-level health integration;

---
## Core Components

- **AI Avatar**: Lifelike human interface with speech, emotion modeling, and therapeutic behavior;
- **Multimodal AI**: Integration of voice, facial cues, natural language understanding, and behavioral mirroring;
- **Therapy Logic**: Supervised implementation of CBT, ACT, and supportive interaction models;
- **Research Platform**: Designed for continuous validation and academic collaboration;
- **Freemium Interface**: Accessible web-based tool with potential for broader population impact;
---
## Value to Academic and Clinical Partners

- Access to a cutting-edge digital research platform;
- Opportunity to co-develop protocols for AI-assisted support systems;
- Long-term potential to scale clinical capacity, especially in early-stage psychological care;
- Contribution to ethics, methodology, and safety standards for AI in psychotherapy;
---
## Differentiators

- **Not a chatbot** – full-spectrum virtual therapist experience;
- **Clinically backed** – developed in partnership with real-world therapists;
- **Ethics-by-design** – safety net features, escalation protocols, data privacy by design;
- **Global reach** – accessible in underserved markets (e.g. MENA, Asia, post-conflict zones);
- **Social impact** – bridges mental health treatment gap at scale;